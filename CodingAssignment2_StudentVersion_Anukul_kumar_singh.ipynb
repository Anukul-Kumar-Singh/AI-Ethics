{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CqKMHHrpTsp"
      },
      "source": [
        "# Assignment 2 : Mitigating Algorithmic Biases\n",
        "Anukul K Singh <br>\n",
        "Mar 11th 2024\n",
        "\n",
        "In this assignment, we will explore practical strategies for mitigating algorithmic bias, focusing on the COMPAS dataset discussed in class. Your task is to complete the provided code blocks to ensure they function as expected. Carefully review each step in this notebook. When you encounter a placeholder marked with \"###replace this with your own code!!!\", replace it with the appropriate code."
      ],
      "id": "7CqKMHHrpTsp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoXKKi63pTst"
      },
      "source": [
        "## 1. Mitigating bias in recidivism risk prediction.\n",
        "\n",
        "In this assignment, we'll utilize the COMPAS Dataset to predict recidivism, which refers to the likelihood of a convicted criminal to reoffend. These predictions can influence decisions regarding bail eligibility before a trial. The ProPublica investigation highlighted significant false positive rates for African American arrestees, demonstrating the algorithm's disparate impact."
      ],
      "id": "RoXKKi63pTst"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EI91JYO8pTsu"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "EI91JYO8pTsu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUX1kxjOpTsv"
      },
      "source": [
        "### 1.1 Clean Data\n",
        "\n",
        "To replicate aspects of the original ProPublica analysis, we will clean the COMPAS Dataset, focusing on its use in recidivism prediction.\n",
        "\n",
        "For our analysis, we will simplify the dataset to include only seven key features: three sensitive attributes (age, sex, and race) and four features related to current charges, prior charge counts, and arrest records.\n",
        "\n",
        "As our label, we look at if the individual did actually commit another crime within a 2-year window of their arrest."
      ],
      "id": "mUX1kxjOpTsv"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "PolQ16eNpTsw",
        "outputId": "91279216-7e38-426f-d3c9-29b06a9b2299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num rows after filtering: 6172\n",
            "Num with two-year recidivism: 2809\n",
            "Features Matrix (below):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  groups  \\\n",
              "0   69              0               0                0             0       0   \n",
              "1   34              0               0                0             0       1   \n",
              "2   24              0               0                1             4       1   \n",
              "5   44              0               0                0             0       0   \n",
              "6   41              0               0                0            14       0   \n",
              "\n",
              "   sex_Male  c_charge_degree_M  \n",
              "0      True              False  \n",
              "1      True              False  \n",
              "2      True              False  \n",
              "5      True               True  \n",
              "6      True              False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04e9c930-7b73-4698-8f4d-a332c8d261f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>juv_fel_count</th>\n",
              "      <th>juv_misd_count</th>\n",
              "      <th>juv_other_count</th>\n",
              "      <th>priors_count</th>\n",
              "      <th>groups</th>\n",
              "      <th>sex_Male</th>\n",
              "      <th>c_charge_degree_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04e9c930-7b73-4698-8f4d-a332c8d261f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04e9c930-7b73-4698-8f4d-a332c8d261f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04e9c930-7b73-4698-8f4d-a332c8d261f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00d86306-ffcc-4413-8872-b56f60d12dd8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00d86306-ffcc-4413-8872-b56f60d12dd8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00d86306-ffcc-4413-8872-b56f60d12dd8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 6172,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 18,\n        \"max\": 96,\n        \"num_unique_values\": 65,\n        \"samples\": [\n          83,\n          80,\n          69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"juv_fel_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"juv_misd_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5,\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"juv_other_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          6,\n          1,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"priors_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 38,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          38,\n          15,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"groups\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex_Male\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"c_charge_degree_M\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "csv_url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
        "\n",
        "# Read the CSV file directly into a pandas DataFrame\n",
        "raw_data = pd.read_csv(csv_url)\n",
        "raw_data.head()\n",
        "\n",
        "# From the original compas analysis\n",
        "df = raw_data[((raw_data['days_b_screening_arrest'] <=30) &\n",
        "      (raw_data['days_b_screening_arrest'] >= -30) &\n",
        "      (raw_data['is_recid'] != -1) &\n",
        "      (raw_data['c_charge_degree'] != 'O') &\n",
        "      (raw_data['score_text'] != 'N/A')\n",
        "     )]\n",
        "\n",
        "print('Num rows after filtering: %d' % len(df))\n",
        "print('Num with two-year recidivism: %d' % sum(df['two_year_recid'] == 1))\n",
        "\n",
        "features = ['age', 'race', 'sex',\n",
        "            'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
        "            'priors_count', 'c_charge_degree']\n",
        "\n",
        "y = df['two_year_recid'].copy()\n",
        "X = df[features].copy()\n",
        "\n",
        "## For the purpose of this analysis, we want to examine the disparate impact on African Americans.\n",
        "## We will group all non-African American arrestees into a single group (group=0)\n",
        "## so that there are only two racial groups.\n",
        "\n",
        "X['groups'] = np.where(X['race'] == 'African-American', 1, 0)\n",
        "X = pd.get_dummies(X, columns = ['sex', 'c_charge_degree'])\n",
        "X.drop(['race', 'sex_Female', 'c_charge_degree_F'], inplace = True, axis=1)\n",
        "print('Features Matrix (below):')\n",
        "X.head()"
      ],
      "id": "PolQ16eNpTsw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_sg3XjrpTsx"
      },
      "source": [
        "### 1.2 Split Data and Examine Recidivism Rates by Group\n",
        "\n",
        "Split the dataset into training and testing subsets. Analyze the recidivism rates across different groups within the dataset to understand potential disparities."
      ],
      "id": "p_sg3XjrpTsx"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_y8Ys0MpTsx",
        "outputId": "ecc8f516-d3a1-42cd-ad64-f6d01a4fd126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% African-American in train:  0.5124569576665992\n",
            "% Others in train:  0.48754304233340084\n",
            "% African-American in test:  0.5222672064777328\n",
            "% Others in test:  0.47773279352226716\n",
            "Difference in Recidivism Rate between Groups in Training Data:  0.14200462747815584\n",
            "Difference in Recidivism Rate between Groups in Test Data:  0.13341216660097227\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)\n",
        "\n",
        "# Calculate the percentage of groups in the training and testing datasets\n",
        "percent_aa_train = X_train['groups'].mean()\n",
        "percent_others_train = 1 - percent_aa_train\n",
        "\n",
        "percent_aa_test = X_test['groups'].mean()\n",
        "percent_others_test = 1 - percent_aa_test\n",
        "\n",
        "print('% African-American in train: ', percent_aa_train)\n",
        "print('% Others in train: ', percent_others_train)\n",
        "\n",
        "print('% African-American in test: ', percent_aa_test)\n",
        "print('% Others in test: ', percent_others_test)\n",
        "\n",
        "# Calculate the recidivism rate differences\n",
        "def recidivism_rate_difference(X, y):\n",
        "    # Create a DataFrame from the groups and labels to facilitate calculations\n",
        "    data = pd.DataFrame({'Group': X['groups'], 'Recidivism': y})\n",
        "    # Calculate recidivism rates by group\n",
        "    rates = data.groupby('Group')['Recidivism'].mean()\n",
        "    # Difference between the groups\n",
        "    return abs(rates.diff().iloc[-1])\n",
        "\n",
        "diff_train = recidivism_rate_difference(X_train, y_train)\n",
        "diff_test = recidivism_rate_difference(X_test, y_test)\n",
        "\n",
        "print('Difference in Recidivism Rate between Groups in Training Data: ',\n",
        "     diff_train)\n",
        "\n",
        "print('Difference in Recidivism Rate between Groups in Test Data: ',\n",
        "     diff_test)"
      ],
      "id": "W_y8Ys0MpTsx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83ApmvMMpTsy"
      },
      "source": [
        "### 1.3 - Basic Model\n",
        "Fit an out-of-the-box ```RandomForestClassifier``` from ```sklearn```. Use the ```predict``` method to return the model's predictions."
      ],
      "id": "83ApmvMMpTsy"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WgdHstUnpTsy"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(random_state = 1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#predictions on the testing set\n",
        "y_hat = clf.predict(X_test)"
      ],
      "id": "WgdHstUnpTsy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EHkjhggpTsz"
      },
      "source": [
        "### 1.4 Compute Metrics\n",
        "Your task is to develop a function that:\n",
        "\n",
        "* ***Takes as input***: the model's predictions on the test set, the actual observed outcomes on the test set, and the test features.\n",
        "* ***Returns***: group-level accuracy, false-positive rate, precision, and recall metrics.\n",
        "\n",
        "This function will be instrumental in assessing the fairness and effectiveness of our predictive model across different demographic groups.\n"
      ],
      "id": "4EHkjhggpTsz"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hY5Dv2yHpTsz"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_hat,\n",
        "                    y_test,\n",
        "                    X_test):\n",
        "\n",
        "    test = X_test.copy()\n",
        "    test['outcome'] = y_test\n",
        "    test['predicted'] = y_hat\n",
        "\n",
        "   # Calculating metrics for group 0 (Others)\n",
        "    TP_0 = ((test['predicted'] == 1) & (test['outcome'] == 1) & (test['groups'] == 0)).sum()\n",
        "    FP_0 = ((test['predicted'] == 1) & (test['outcome'] == 0) & (test['groups'] == 0)).sum()\n",
        "    TN_0 = ((test['predicted'] == 0) & (test['outcome'] == 0) & (test['groups'] == 0)).sum()\n",
        "    FN_0 = ((test['predicted'] == 0) & (test['outcome'] == 1) & (test['groups'] == 0)).sum()\n",
        "\n",
        "    # Calculating metrics for group 1 (African-American)\n",
        "    TP_1 = ((test['predicted'] == 1) & (test['outcome'] == 1) & (test['groups'] == 1)).sum()\n",
        "    FP_1 = ((test['predicted'] == 1) & (test['outcome'] == 0) & (test['groups'] == 1)).sum()\n",
        "    TN_1 = ((test['predicted'] == 0) & (test['outcome'] == 0) & (test['groups'] == 1)).sum()\n",
        "    FN_1 = ((test['predicted'] == 0) & (test['outcome'] == 1) & (test['groups'] == 1)).sum()\n",
        "\n",
        "    # Calculate measures for g0\n",
        "    accuracy_g0 = (TP_0 + TN_0) / (TP_0 + FP_0 + TN_0 + FN_0)\n",
        "    precision_g0 = TP_0 / (TP_0 + FP_0) if (TP_0 + FP_0) > 0 else 0\n",
        "    recall_g0 = TP_0 / (TP_0 + FN_0) if (TP_0 + FN_0) > 0 else 0\n",
        "    false_positive_rate_g0 = FP_0 / (FP_0 + TN_0) if (FP_0 + TN_0) > 0 else 0\n",
        "\n",
        "    # Calculate measures for g1\n",
        "    accuracy_g1 = (TP_1 + TN_1) / (TP_1 + FP_1 + TN_1 + FN_1)\n",
        "    precision_g1 = TP_1 / (TP_1 + FP_1) if (TP_1 + FP_1) > 0 else 0\n",
        "    recall_g1 = TP_1 / (TP_1 + FN_1) if (TP_1 + FN_1) > 0 else 0\n",
        "    false_positive_rate_g1 = FP_1 / (FP_1 + TN_1) if (FP_1 + TN_1) > 0 else 0\n",
        "\n",
        "\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "    \"Group\": [\"0-OtherRaces\", \"0-OtherRaces\", \"0-OtherRaces\", \"0-OtherRaces\",\n",
        "              \"1-AfricanAmerican\", \"1-AfricanAmerican\", \"1-AfricanAmerican\", \"1-AfricanAmerican\"],\n",
        "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"FPR\", \"Accuracy\", \"Precision\", \"Recall\", \"FPR\"],\n",
        "    \"Value\": [accuracy_g0, precision_g0, recall_g0, false_positive_rate_g0,\n",
        "              accuracy_g1, precision_g1, recall_g1, false_positive_rate_g1]})\n",
        "\n",
        "    return metrics_df"
      ],
      "id": "hY5Dv2yHpTsz"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDweU565pTsz",
        "outputId": "7165cc9d-6576-4765-bc42-548cebc72937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group      0-OtherRaces  1-AfricanAmerican\n",
            "Metric                                    \n",
            "Accuracy       0.649153           0.626357\n",
            "FPR            0.252660           0.390769\n",
            "Precision      0.517766           0.618619\n",
            "Recall         0.476636           0.643750\n"
          ]
        }
      ],
      "source": [
        "metrics_df = compute_metrics(y_hat = y_hat, y_test = y_test, X_test = X_test)\n",
        "\n",
        "print(metrics_df.pivot(index='Metric', columns='Group', values='Value'))"
      ],
      "id": "uDweU565pTsz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyhFib8dpTs0"
      },
      "source": [
        "In this assignment, we focus on ***disparate impact***, illustrated by differences in False Positive Rates (FPR) between African-Americans and other races. A higher FPR for African-Americans means more individuals from this group could be unjustly denied bail if such a model were used in decision-making. Although the baseline model may show higher accuracy, precision, and recall for African-Americans, it also results in a significantly higher FPR for this group. Our goal is to address and mitigate this bias, with a particular focus on reducing the disparate FPR."
      ],
      "id": "RyhFib8dpTs0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8FlYj0GpTs0"
      },
      "source": [
        "## 2. Pre-processing for Bias Mitigation\n",
        "\n",
        "Pre-processing is a strategic approach to mitigate bias, particularly effective when bias in the data may be attributed to how the data were sampled. In the context of our dataset, societal biases could influence lending decisions towards certain demographic groups. By addressing potential sampling biases, we aim to improve the fairness of our predictive model."
      ],
      "id": "I8FlYj0GpTs0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmkXDkrMpTs0"
      },
      "source": [
        "### 2.1 - Reweighting to Correct Sample Bias\n",
        "\n",
        "We will use the approach discussed in class in which we re-weight training instances so that the algorithm learns more from smaller groups than it would in the case where every training instance is weighted equally. In this case, we will upweight training instances from smaller groups, setting the weight for the largest group equal to 1.\n",
        "\n",
        "**Step 1: Identify the size of the most represented group within our dataset.**"
      ],
      "id": "hmkXDkrMpTs0"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HO6xh0WtpTs0"
      },
      "outputs": [],
      "source": [
        "group_counts = X_train['groups'].value_counts()\n",
        "most_represented_group_count = np.max(group_counts)"
      ],
      "id": "HO6xh0WtpTs0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to77QwWGpTs1"
      },
      "source": [
        "**Step 2: Create a lambda function that will generate a weights column using this methodology**"
      ],
      "id": "to77QwWGpTs1"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MDjJYd7EpTs1"
      },
      "outputs": [],
      "source": [
        "X_train['weights'] = X_train['groups'].apply(lambda x: most_represented_group_count / group_counts[x])"
      ],
      "id": "MDjJYd7EpTs1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJL3kYnBpTs1"
      },
      "source": [
        "**Step 3: Create a table showing that the training rows from different groups now have equal weight**"
      ],
      "id": "aJL3kYnBpTs1"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UHBTCOwpTs1",
        "outputId": "03956a11-c8e6-4d7f-c08f-ebe9c278543a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "groups\n",
              "0    2530.0\n",
              "1    2530.0\n",
              "Name: weights, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "X_train.groupby('groups')['weights'].sum()"
      ],
      "id": "2UHBTCOwpTs1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcCGzKorpTs1"
      },
      "source": [
        "We see that this scheme has now equally weights both groups in the training data.\n",
        "\n",
        "### 2.2 Fit, Predict, and Print the Weighted Model Results\n",
        "\n",
        "With the dataset now reweighted to correct for sample bias, proceed to fit the model using this adjusted data. After fitting the model, predict the outcomes and evaluate the model's performance. Specifically, focus on how the reweighting has impacted the model's fairness across different demographic groups by examining changes in key performance metrics."
      ],
      "id": "zcCGzKorpTs1"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfGDqbhCpTs2",
        "outputId": "d3cb5d86-7e10-4935-c297-71121dd27e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group      0-OtherRaces  1-AfricanAmerican\n",
            "Metric                                    \n",
            "Accuracy       0.650847           0.624806\n",
            "FPR            0.247340           0.393846\n",
            "Precision      0.520619           0.616766\n",
            "Recall         0.471963           0.643750\n"
          ]
        }
      ],
      "source": [
        "weights = X_train['weights']\n",
        "X_train.drop(['weights'],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "clf_preprocess = RandomForestClassifier(random_state = 1000)\n",
        "clf_preprocess.fit(X_train, y_train, sample_weight=weights)\n",
        "\n",
        "#predictions on the testing set\n",
        "y_hat_preprocess = clf_preprocess.predict(X_test)\n",
        "\n",
        "metrics_df = compute_metrics(y_hat = y_hat_preprocess, y_test = y_test, X_test = X_test)\n",
        "\n",
        "print(metrics_df.pivot(index='Metric', columns='Group', values='Value'))\n",
        "\n",
        "\n"
      ],
      "id": "cfGDqbhCpTs2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxM5xp-CpTs2"
      },
      "source": [
        "We see that this approach did not reduce the FPR disparity between the groups. This is likely because the two groups are very similar in size in the data, thus sampling bias isn't a likely cause of the ***disparate impact*** we observe."
      ],
      "id": "ZxM5xp-CpTs2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOBZAzHTpTs2"
      },
      "source": [
        "## 3. In-Processing for Bias Mitigation\n",
        "\n",
        "In-processing is particularly effective for addressing bias stemming from ***differential subgroup validity***, where the relationship between predictors and outcomes may differ across groups. To tackle this, we will develop separate models for different demographic groups (in this case, by race). This approach allows the models to more accurately capture and reflect the unique relationships between features and outcomes within each subgroup."
      ],
      "id": "GOBZAzHTpTs2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gse3GP27pTs2"
      },
      "source": [
        "### 3.1 - Split train and test data by group\n",
        "\n",
        "Begin by segregating the dataset into separate training and testing sets by group. This division enables the creation of group-specific models, ensuring that each model is tailored to accurately represent its respective group."
      ],
      "id": "gse3GP27pTs2"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2M3vYEgLpTs2"
      },
      "outputs": [],
      "source": [
        "def split_train_and_test_by_group(X_train, X_test, y_train, y_test):\n",
        "\n",
        "\n",
        "    train = X_train.copy()\n",
        "    test = X_test.copy()\n",
        "    train['outcome'] = y_train\n",
        "    test['outcome'] = y_test\n",
        "\n",
        "    # split train and test by group\n",
        "    train_g1 = train[train['groups']==1]\n",
        "    train_g0 = train[train['groups']==0]\n",
        "    test_g1 = test[test['groups']==1]\n",
        "    test_g0 = test[test['groups']==0]\n",
        "\n",
        "    # separate outcomes from test\n",
        "    y_train_g1 = train_g1['outcome']\n",
        "    y_train_g0 = train_g0['outcome']\n",
        "    y_test_g1 = test_g1['outcome']\n",
        "    y_test_g0 = test_g0['outcome']\n",
        "\n",
        "    X_train_g1 = train_g1.drop(['outcome', 'groups'], axis=1)\n",
        "    X_train_g0 = train_g0.drop(['outcome', 'groups'], axis=1)\n",
        "    X_test_g1 = test_g1.drop(['outcome', 'groups'], axis=1)\n",
        "    X_test_g0 = test_g0.drop(['outcome', 'groups'], axis=1)\n",
        "\n",
        "    return y_train_g1, y_train_g0, y_test_g1, y_test_g0, X_train_g1, X_train_g0, X_test_g1, X_test_g0\n",
        "\n",
        "\n",
        "y_train_g1, y_train_g0, y_test_g1, y_test_g0, \\\n",
        "X_train_g1, X_train_g0, X_test_g1, X_test_g0 = split_train_and_test_by_group(X_train = X_train,\n",
        "                                                                              X_test = X_test,\n",
        "                                                                              y_train = y_train,\n",
        "                                                                              y_test = y_test)\n",
        "\n",
        "\n"
      ],
      "id": "2M3vYEgLpTs2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHhJVgeNpTs3"
      },
      "source": [
        "### 3.2 - Fit models and generate predictions for each group\n",
        "\n",
        "Now, fit separate predictive models for each group using the training data you've prepared. After fitting these models, generate predictions for each group-specific test set."
      ],
      "id": "RHhJVgeNpTs3"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YAChAwDJpTs3"
      },
      "outputs": [],
      "source": [
        "clf_g0 = RandomForestClassifier(random_state=1000)\n",
        "clf_g0.fit(X_train_g0, y_train_g0)\n",
        "clf_g1 = RandomForestClassifier(random_state=1000)\n",
        "clf_g1.fit(X_train_g1, y_train_g1)\n",
        "y_hat_g0 = clf_g0.predict(X_test_g0)\n",
        "y_hat_g1 = clf_g1.predict(X_test_g1)"
      ],
      "id": "YAChAwDJpTs3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKOKiV-CpTs3"
      },
      "source": [
        "### 3.3 - Write a function to merge data back together and return a combined ```y_hat```, ```y_test```, and ```X_test```\n",
        "\n",
        "After generating group-specific predictions, write a function that merges these predictions back into a single dataset. This function should return combined y_hat (predicted outcomes), y_test (actual outcomes), and X_test (test features) for the entire test dataset. This recombination is essential for evaluating the overall performance of our bias mitigation strategy across all groups."
      ],
      "id": "xKOKiV-CpTs3"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YpSBgQuopTs3"
      },
      "outputs": [],
      "source": [
        "def merge_separate_models(y_hat_g1, y_hat_g0, y_test_g1, \\\n",
        "                          y_test_g0, X_test_g1, X_test_g0):\n",
        "\n",
        "    test_g1 = X_test_g1.copy()\n",
        "    test_g1['groups'] = 1\n",
        "    test_g1['outcome'] = y_test_g1\n",
        "    test_g1['pred'] = y_hat_g1\n",
        "\n",
        "    test_g0 = X_test_g0.copy()\n",
        "    test_g0['groups'] = 0\n",
        "    test_g0['outcome'] = y_test_g0\n",
        "    test_g0['pred'] = y_hat_g0\n",
        "\n",
        "    # Merge back together\n",
        "    test = pd.concat([test_g0, test_g1])\n",
        "\n",
        "    y_test = test['outcome']\n",
        "    y_hat = test['pred']\n",
        "    X_test = test.drop(['outcome','pred'], axis=1)\n",
        "\n",
        "    return y_test, y_hat, X_test\n",
        "\n",
        "\n",
        "y_test_combined, \\\n",
        "y_hat_combined, \\\n",
        "X_test_combined = merge_separate_models(y_hat_g1 = y_hat_g1,\n",
        "                                        y_hat_g0 = y_hat_g0,\n",
        "                                        y_test_g1 = y_test_g1,\n",
        "                                        y_test_g0 = y_test_g0,\n",
        "                                        X_test_g1 = X_test_g1,\n",
        "                                        X_test_g0 = X_test_g0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "YpSBgQuopTs3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irdXK4OcpTs3"
      },
      "source": [
        "### 3.4 Print model output"
      ],
      "id": "irdXK4OcpTs3"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkXjl9sIpTs4",
        "outputId": "13a12c43-90d1-483d-80e7-3d3a09b0a0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group      0-OtherRaces  1-AfricanAmerican\n",
            "Metric                                    \n",
            "Accuracy       0.654237           0.609302\n",
            "FPR            0.220745           0.412308\n",
            "Precision      0.528409           0.601190\n",
            "Recall         0.434579           0.631250\n"
          ]
        }
      ],
      "source": [
        "metrics_df = compute_metrics(y_hat = y_hat_combined,\n",
        "                             y_test = y_test_combined,\n",
        "                             X_test = X_test_combined)\n",
        "\n",
        "print(metrics_df.pivot(index='Metric', columns='Group', values='Value'))"
      ],
      "id": "JkXjl9sIpTs4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MalIEDAapTs4"
      },
      "source": [
        "We see that the approach does not improve the disparity in the FPR either. This points to the fact that **differential subgroup validity** may be less relevant in this case of bias, and if it is relevant, training classifiers that are group-specific does not address the problem."
      ],
      "id": "MalIEDAapTs4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJjmjL4WpTs4"
      },
      "source": [
        "## 4. Post-processing for Bias Mitigation.\n",
        "\n",
        "This section introduces post-processing techniques as a means to further mitigate bias in our predictive models. Post-processing involves adjusting the model's output after the initial predictions have been made, offering another layer of bias correction. Sometimes, if there is significant bias in how outcomes are created (e.g. socially biased disparities in arrest rates amongst racial groups), post-processing may be the only method of correction."
      ],
      "id": "OJjmjL4WpTs4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lXwzCtJpTs4"
      },
      "source": [
        "### 4.1 Creating Different Thresholds for Different Groups\n",
        "\n",
        "Until now, our models have applied the standard prediction threshold of 0.5, meaning a prediction label of 1 (positive) is assigned if the predicted probability exceeds this value. As an alternative, we'll explore optimizing prediction thresholds for each demographic group. Our goal is to enhance overall accuracy without infringing upon fairness principles, particularly avoiding disparate impact manifested through variations in False Positive Rates (FPR) between groups.\n",
        "\n",
        "To achieve this, we will experiment with various threshold values above 0.5 (since 0.5 is our baseline). It's important to work with predicted probabilities rather than binary class labels, as this allows us to finely tune our threshold for decision-making."
      ],
      "id": "3lXwzCtJpTs4"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5l0gutF5pTs4"
      },
      "outputs": [],
      "source": [
        "threshold_values = [i/100 for i in range(50, 90)]\n",
        "y_hat_probs = clf.predict_proba(X_test)[:,1]"
      ],
      "id": "5l0gutF5pTs4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vUl_7QWpTs4"
      },
      "source": [
        "Now, create a function that takes as input the true outcomes (y_true), the predicted probabilities (y_proba), and the list of threshold values previously created (threshold_values) and returns a dataframe that contains all possible combinations of threshold values for each group, as well as model accuracy and the difference in false positive rate."
      ],
      "id": "_vUl_7QWpTs4"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ApTR-VmcjgsN"
      },
      "outputs": [],
      "source": [
        "def evaluate_group_thresholds(y_true, y_proba, groups, threshold_values):\n",
        "\n",
        "    unique_groups = np.unique(groups)\n",
        "    # This enumerates all possible options for threshold values within the range specified\n",
        "    all_combinations = list(product(threshold_values, repeat=len(unique_groups)))\n",
        "\n",
        "    # Prepare a list to collect results\n",
        "    results = []\n",
        "\n",
        "    for combination in all_combinations:\n",
        "        group_thresholds = {group: threshold for group, threshold in zip(unique_groups, combination)}\n",
        "\n",
        "        # Apply group-specific thresholds to generate predictions\n",
        "        y_pred = np.zeros(y_true.shape)\n",
        "        for group, threshold in group_thresholds.items():\n",
        "            group_mask = (groups == group)\n",
        "            y_pred[group_mask] = (y_proba[group_mask] > threshold).astype(int)\n",
        "\n",
        "        # Calculate FPR for each group\n",
        "        fprs = {}\n",
        "        for group in unique_groups:\n",
        "            group_mask = (groups == group)\n",
        "            group_true = y_true[group_mask]\n",
        "            group_pred = y_pred[group_mask]\n",
        "\n",
        "            FP = len(group_true[(group_true == 0) & (group_pred == 1)])\n",
        "            TN = len(group_true[(group_true == 0) & (group_pred == 0)])\n",
        "            fprs[group] = FP / (FP + TN)\n",
        "\n",
        "        # Calculate overall accuracy\n",
        "        overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        # Calculate the FPR difference\n",
        "        fpr_diff = fprs[unique_groups[0]] - fprs[unique_groups[1]]\n",
        "        # Create a row of data as a list of four items (see columns for below for ordering)\n",
        "        row = list(combination) + [overall_accuracy, fpr_diff]\n",
        "        results.append(row)\n",
        "\n",
        "    # Create a DataFrame from the collected results\n",
        "    columns = ['Threshold 0', 'Threshold 1', 'Model Accuracy', 'FPR Difference']\n",
        "    results_df = pd.DataFrame(results, columns=columns)\n",
        "\n",
        "    return results_df\n",
        "\n",
        "\n",
        "results = evaluate_group_thresholds(y_true = y_test,\n",
        "                                    y_proba = y_hat_probs,\n",
        "                                    groups = X_test['groups'],\n",
        "                                    threshold_values = threshold_values)"
      ],
      "id": "ApTR-VmcjgsN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqU7K2G9pTs5"
      },
      "source": [
        "Now that you have evaluated many combinations of thresholds, lets see where the thresholds fall below a **0.01** difference in false positive rate, and let's pick the row in this range with the highest model accuracy."
      ],
      "id": "lqU7K2G9pTs5"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFEH0u-1pTs9",
        "outputId": "d8059a8a-1411-4c9c-8be9-3ccfe693b87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold 0       0.570000\n",
            "Threshold 1       0.710000\n",
            "Model Accuracy    0.650202\n",
            "FPR Difference   -0.000270\n",
            "Name: 301, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Filter the DataFrame for rows where the absolute FPR difference is less than 0.01\n",
        "fpr_threshold_subset = results[results['FPR Difference'].abs()<0.01]\n",
        "\n",
        "# Find the index of the row with the maximum accuracy in the filtered subset\n",
        "max_accuracy_index = fpr_threshold_subset['Model Accuracy'].idxmax()\n",
        "\n",
        "# Retrieve the row with the maximum accuracy\n",
        "max_accuracy_row = fpr_threshold_subset.loc[max_accuracy_index]\n",
        "print(max_accuracy_row)"
      ],
      "id": "RFEH0u-1pTs9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3iZqqlkpTs9"
      },
      "source": [
        "Finally, let's apply these chosen thresholds to our test-set predictions, and then calculate our standard set of metrics."
      ],
      "id": "o3iZqqlkpTs9"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OEh4FJfepTs-"
      },
      "outputs": [],
      "source": [
        "def generate_group_level_labels(y_proba, groups, max_accuracy_row):\n",
        "\n",
        "    y_pred = np.zeros(y_proba.shape)\n",
        "    for group in groups.unique():\n",
        "        group_mask = (groups == group)\n",
        "        y_pred[group_mask] = (y_proba[group_mask] > max_accuracy_row[f'Threshold {group}']).astype(int)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "y_hat_thresholds = generate_group_level_labels(y_proba = y_hat_probs,\n",
        "                                               groups = X_test['groups'],\n",
        "                                               max_accuracy_row = max_accuracy_row)\n",
        "\n"
      ],
      "id": "OEh4FJfepTs-"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiyBRmnopTs-",
        "outputId": "ab11a7f4-0330-4cfc-af1f-3f14a5d59046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group      0-OtherRaces  1-AfricanAmerican\n",
            "Metric                                    \n",
            "Accuracy       0.674576           0.627907\n",
            "FPR            0.178191           0.178462\n",
            "Precision      0.570513           0.704082\n",
            "Recall         0.415888           0.431250\n"
          ]
        }
      ],
      "source": [
        "metrics_df = compute_metrics(y_hat = y_hat_thresholds,\n",
        "                             y_test = y_test,\n",
        "                             X_test = X_test)\n",
        "\n",
        "print(metrics_df.pivot(index='Metric', columns='Group', values='Value'))"
      ],
      "id": "QiyBRmnopTs-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N66saxscpTs-"
      },
      "source": [
        "Well done! We see that this post-processing technique has significantly reduced the disparity in False Positive Rate! However, this may be a case of **disparate treatment**, as there are now effectively different decision rules for different racial groups."
      ],
      "id": "N66saxscpTs-"
    }
  ],
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
